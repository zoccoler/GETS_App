{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de tratamento da lista de equipamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_equip_data():\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    for file in os.listdir(\".\\ListaEqpt\"):\n",
    "        if file.endswith(\".xls\"):\n",
    "            file_path = os.path.join(\".\\ListaEqpt\", file)\n",
    "    lista_eqp = pd.read_excel(file_path,skiprows=3,header=2,dtype={'Patrimônio': str, 'Tipo Equipamento': str})\n",
    "    lista_eqp = lista_eqp.drop(['Localização','Modelo','Fornecedor','Núm. Doc. da Aquisição','Nota Fiscal','Garantia',\n",
    "                            'Parecer Desativação','Contrato','Vida Útil','Equipamento Crítico',\n",
    "                               'Descrição Complementar'], axis=1)\n",
    "    lista_eqp['Aquisição'] = pd.to_datetime(lista_eqp['Aquisição'],dayfirst=True)\n",
    "    lista_eqp['Data Desativação'] = pd.to_datetime(lista_eqp['Data Desativação'],dayfirst=True)\n",
    "    lista_eqp.sort_values(by=['Aquisição'], inplace=True)\n",
    "    return(lista_eqp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_equip_data(lista_eqp):\n",
    "    import pandas as pd\n",
    "    # Delete invalid dates ( =-1, which is equivalent to dates before 1900)\n",
    "    lista_eqp = lista_eqp.drop(lista_eqp[lista_eqp['Aquisição'] < pd.to_datetime(1900, format='%Y')].index)\n",
    "    \n",
    "    # Delete equipments with 'DESATIVADO=SIM' AND without disable date\n",
    "    lista_eqp = lista_eqp.drop(lista_eqp[(lista_eqp['Desativado']=='SIM') & (pd.isna(lista_eqp['Data Desativação']))].index)\n",
    "    \n",
    "    # Delete equipments tagged with 'DESATIVADO=NÃO' AND without disable date AND also tagged with 'BAIXADO=SIM'\n",
    "    lista_eqp = lista_eqp.drop(lista_eqp[(lista_eqp['Desativado']=='NÃO') & (pd.isna(lista_eqp['Data Desativação'])) & ((lista_eqp['Baixado']=='SIM'))].index)\n",
    "    \n",
    "    \n",
    "    # Consider active (i.e., remove disable date) equipments tagged with 'DESATIVADO=NÃO' AND 'BAIXADO=NÃO', even if they have disable date \n",
    "    # Flags for filtering\n",
    "    is_not_disabled = lista_eqp['Desativado']=='NÃO'\n",
    "    is_not_down = lista_eqp['Baixado']=='NÃO'\n",
    "    has_disable_date = pd.notna(lista_eqp['Data Desativação']) \n",
    "    lista_eqp.loc[lista_eqp[is_not_disabled & has_disable_date & is_not_down].index , ['Data Desativação']] = pd.NaT\n",
    "    \n",
    "    #Consider active equipments tagged with 'DESATIVADO=SIM', AND that have an disable date, \n",
    "    #     AND tagged with 'PERMITIR O.S.=SIM', AND tagged with 'BAIXADO=NÃO'\n",
    "    # Flags for filtering\n",
    "    is_disabled = lista_eqp['Desativado']=='SIM'\n",
    "    has_disable_date = pd.notna(lista_eqp['Data Desativação'])\n",
    "    allow_OS = lista_eqp['Permitir O.S.']=='SIM'\n",
    "    is_not_down = lista_eqp['Baixado']=='NÃO'\n",
    "    lista_eqp.loc[lista_eqp[(is_disabled & has_disable_date & allow_OS & is_not_down)].index,['Data Desativação']] = pd.NaT\n",
    "    \n",
    "    return(lista_eqp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_equip_data(lista_eqp):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # Copy dataframe\n",
    "    lista_eqp2 = lista_eqp.copy()\n",
    "    # On original dataframe, create column 'Ativo' (with Trues) and renames column 'Aquisição' as 'Data'\n",
    "    lista_eqp.loc[:,'Ativo'] = np.ones(len(lista_eqp),dtype=bool)\n",
    "    lista_eqp.rename(columns={'Aquisição':'Data'}, inplace=True)\n",
    "    # On dataframe copy, remove active equipments and creates column 'Ativo' (with Falses)\n",
    "    # also removes column 'Aquisição' and renames column 'Data Desativação' as 'Data'\n",
    "    lista_eqp2 = lista_eqp2[pd.notna(lista_eqp2['Data Desativação'])]\n",
    "    lista_eqp2.loc[:,'Ativo'] = np.zeros(len(lista_eqp2),dtype=bool)\n",
    "    lista_eqp2 = lista_eqp2.drop(['Aquisição'], axis=1)\n",
    "    lista_eqp2.rename(columns={'Data Desativação':'Data'}, inplace=True)\n",
    "    # Concatenates original and copy\n",
    "    double_lista_eqp = pd.concat([lista_eqp,lista_eqp2],sort=True)\n",
    "    # Redesign indexes as double indexes 'Data' and 'Patrimônio'\n",
    "    double_lista_eqp = double_lista_eqp.set_index(['Data','Patrimônio'])\n",
    "    double_lista_eqp = double_lista_eqp.sort_index()\n",
    "    # Remove duplicates\n",
    "    double_lista_eqp = double_lista_eqp[~double_lista_eqp.index.duplicated()]\n",
    "    \n",
    "    return(double_lista_eqp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_equips_data():\n",
    "    df = load_equip_data()\n",
    "    df = clean_equip_data(df)\n",
    "    df = arrange_equip_data(df)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equip_amount(df,equip,start_date=0, end_date=10):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    selected_equip = df['Tipo Equipamento']==equip\n",
    "    acquired = df['Ativo']==True\n",
    "    deactivated = df['Ativo']==False\n",
    "    \n",
    "    equip_acquired_cumsum = (selected_equip & acquired).cumsum()\n",
    "    equip_deactivated_cumsum = (selected_equip & deactivated).cumsum()\n",
    "    \n",
    "    equip_amount = equip_acquired_cumsum - equip_deactivated_cumsum\n",
    "    equip_amount_data = df[selected_equip].copy()\n",
    "    equip_amount_data.loc[:,'Quantidade de Equipamentos'] = equip_amount\n",
    "    # Sort dates in accending order\n",
    "    equip_amount_data.sort_index(level=0,inplace=True)\n",
    "#     print(equip_amount_data[equip_amount_data['Ativo'].isna()])\n",
    "    return(equip_amount_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de tratamento das OS Encerradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_four_month(year,n):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    file_template = '.\\OSEncerrada\\OSEncerrada_{year}_0{n}.xls'\n",
    "    file_name = file_template.format(year=year,n=n)\n",
    "    try:\n",
    "        closed_OS = pd.read_excel(file_name,skiprows=3,header=2,dtype={'Núm. O.S.': str, 'Tipo Equip.':str, 'Patrimônio': str, 'Tempo SOS-OSP (horas)':np.float64})\n",
    "    except:\n",
    "        return(pd.DataFrame({'P' : []}))\n",
    "    closed_OS = closed_OS.drop(['Grupo','Programa MP','Modelo','Duração (dias)','Equipamento Crítico',\n",
    "                               'Tempo SOS-OSP (dias)','Indisponibilidade (dias)'], axis=1)\n",
    "    closed_OS['Abertura'] = pd.to_datetime(closed_OS['Abertura'],dayfirst=True)\n",
    "    closed_OS['Encerramento'] = pd.to_datetime(closed_OS['Encerramento'],dayfirst=True)\n",
    "    closed_OS.sort_values(by=['Abertura'], inplace=True)\n",
    "    closed_OS.loc[closed_OS['Tempo SOS-OSP (horas)']==0, 'Tempo SOS-OSP (horas)'] = 1/60\n",
    "    return(closed_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_OS_data(start_date=2010, end_date=2021):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    whole_data = []\n",
    "    for y in np.arange(start_date,end_date):\n",
    "        data = []\n",
    "        for i in range(1,5):\n",
    "            four_m_data = get_four_month(y, i)\n",
    "            if not four_m_data.empty:\n",
    "                data.append(four_m_data)\n",
    "        whole_data.append(pd.concat(data))\n",
    "    whole_data = pd.concat(whole_data)\n",
    "    return(whole_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de tratamento de OS Pendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_open_OS_data(df):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    for file in os.listdir(\".\\OSPendente\"):\n",
    "        if file.endswith(\".xls\"):\n",
    "            file_path = os.path.join(\".\\OSPendente\", file)\n",
    "    open_OS = pd.read_excel(file_path,skiprows=3,header=2,dtype={'Num.': str, 'Patrimônio': str, 'Estado':str})\n",
    "    open_OS = open_OS.drop(['Núm.Orgão','N. Série','Grupo','Marca','Modelo','No Nec','Equipamento Crítico'], axis=1)\n",
    "    # Put dates in the right format\n",
    "    open_OS['Dt. Abertura'] = pd.to_datetime(open_OS['Dt. Abertura'],dayfirst=True)\n",
    "    open_OS['Dt. Última Transição'] = pd.to_datetime(open_OS['Dt. Última Transição'],dayfirst=True)\n",
    "    open_OS.sort_values('Dt. Abertura', inplace=True)\n",
    "    \n",
    "    # Find OS that are ready to treat separatedly\n",
    "    OS_ready = open_OS['Estado']=='OSP - OS Pronta'\n",
    "    open_OS = open_OS.drop(['Estado'], axis=1)\n",
    "    # Create column 'Processada' (with Falses) (at first treat all OS as unfinished)\n",
    "    open_OS.loc[:,'Processada'] = np.zeros(len(open_OS),dtype=bool)\n",
    "    # Create a copy with just the OS that are ready\n",
    "    open_OS_ready = open_OS.loc[OS_ready].copy()\n",
    "    # Change status of column 'Processada' to True in this copy and redefines 'Dt. Abertura' as 'Dt. Última Transição'\n",
    "    open_OS_ready.loc[:,'Processada'] = True\n",
    "    open_OS_ready.loc[:,'Dt. Abertura'] = open_OS_ready.loc[:,'Dt. Última Transição']\n",
    "    #################################\n",
    "    #### Now, in both dataframes ####\n",
    "    # Insert new column 'Encerramento' (empty), but attribute 'Dt. Última Transição' to OS that are ready\n",
    "    open_OS.insert(4,'Encerramento','')\n",
    "    open_OS.loc[OS_ready,'Encerramento'] = open_OS.loc[OS_ready,'Dt. Última Transição']\n",
    "    open_OS_ready.insert(4,'Encerramento','')\n",
    "    open_OS_ready.loc[:,'Encerramento'] = open_OS_ready.loc[:,'Dt. Última Transição']\n",
    "    # Insert new column 'Classe' (with 'Manutenção Corretiva'). Obs: tha excel table was generated with the \n",
    "    #    filter 'Manutenção Corretiva', so all OS's should be of this class\n",
    "    open_OS.insert(1,'Classe','Manutenção Corretiva')\n",
    "    open_OS_ready.insert(1,'Classe','Manutenção Corretiva')\n",
    "    # delete the column 'Dt. Última Transição' (not necessary anymore) and renames some column to match those of the \n",
    "    #    closed_OS dataframe\n",
    "    open_OS = open_OS.drop(['Dt. Última Transição'], axis=1)\n",
    "    open_OS_ready = open_OS_ready.drop(['Dt. Última Transição'], axis=1)\n",
    "    open_OS.rename(columns={\"Num.\": \"Núm. O.S.\", \"Dt. Abertura\": \"Abertura\"},inplace=True)\n",
    "    open_OS_ready.rename(columns={\"Num.\": \"Núm. O.S.\", \"Dt. Abertura\": \"Abertura\"},inplace=True)\n",
    "    ################################\n",
    "    # Concatenate closed_OS dataframe with open_OS and open_OS_ready dataframes\n",
    "    df = pd.concat([df,open_OS,open_OS_ready],ignore_index=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_OS_data(whole_data):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # Copy dataframe\n",
    "    whole_data2 = whole_data.copy()\n",
    "    # On original dataframe, create column 'Processada' (with Falses)\n",
    "    whole_data.loc[:,'Processada'] = np.zeros(len(whole_data),dtype=bool)\n",
    "    # load open_OS data and concatenate it with original dataframe (whole_data, which contains closed OS's)\n",
    "    whole_data = load_open_OS_data(whole_data)\n",
    "    # On copy, changes date 'Abertura' to the moment when the OS was processed\n",
    "    whole_data2['Abertura'] = whole_data2['Abertura'] + pd.to_timedelta(whole_data2['Tempo SOS-OSP (horas)'], unit='h')\n",
    "    # On copy, create column 'Processada' (with Trues)\n",
    "    whole_data2.loc[:,'Processada'] = np.ones(len(whole_data2),dtype=bool)\n",
    "    # Concatenate data\n",
    "    double_whole_data = pd.concat([whole_data,whole_data2])\n",
    "    # Renames column 'Abertura' as 'Data'\n",
    "    double_whole_data.rename(columns={'Abertura':'Data'}, inplace=True)\n",
    "    # Redesign indexes as double indexes 'Data' and 'Núm. O.S.'\n",
    "    double_whole_data = double_whole_data.set_index(['Data','Núm. O.S.'])\n",
    "    # Sort dates in accending order\n",
    "    double_whole_data = double_whole_data.sort_index()\n",
    "    # Remove duplicates (I downloaded the same day twice somewhere)\n",
    "    double_whole_data = double_whole_data[~double_whole_data.index.duplicated()]\n",
    "    return(double_whole_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_OS_data(start_date=2010, end_date=2021):\n",
    "    df = load_OS_data(start_date, end_date)\n",
    "    df = arrange_OS_data(df)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equip_break_rate(df,equip,start_date=0, end_date=10):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    selected_equip = df['Tipo Equip.']==equip\n",
    "\n",
    "    maintenance_type = 'Manutenção Corretiva'\n",
    "    selected_maintenance = df['Classe']==maintenance_type\n",
    "    opened = df['Processada']==False\n",
    "    closed = df['Processada']==True\n",
    "\n",
    "    OS_opened_cumsum = (selected_equip & selected_maintenance & opened).cumsum()\n",
    "    OS_processed_cumsum = (selected_equip & selected_maintenance & closed).cumsum()\n",
    "\n",
    "    break_rate = OS_opened_cumsum - OS_processed_cumsum\n",
    "    break_rate_data = df[selected_equip & selected_maintenance].copy()\n",
    "    if break_rate_data.empty==False:\n",
    "        break_rate_data['Taxa de Quebra'] = break_rate\n",
    "    return(break_rate_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de aquisição de equipamentos totais e disponíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_equip(selected_equip,equips_data,OS_data):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # get selected equipment amount (over time)\n",
    "    equip_amount_data = get_equip_amount(equips_data,selected_equip)\n",
    "    \n",
    "    # get selected equipment break rate (over time)\n",
    "    break_data = get_equip_break_rate(OS_data,selected_equip)\n",
    "        \n",
    "    # Replaces content of columns 'Ativo' and 'Processada' by 1 (when equipment is acquired or fixed) or -1 (when equipment\n",
    "    #       is disabled or broken)\n",
    "    dates1 = equip_amount_data.index.get_level_values(0)\n",
    "    amounts = equip_amount_data['Ativo'].astype(int)\n",
    "    amounts[amounts==0] = -1\n",
    "    \n",
    "    if break_data.empty:\n",
    "#         breaks = break_data\n",
    "        available_equips = pd.concat([amounts])\n",
    "#         print(available_equips)\n",
    "        available_equips.rename(0, inplace=True)\n",
    "    else:\n",
    "        dates2 = break_data.index.get_level_values(0)\n",
    "        breaks = break_data['Processada'].astype(int)\n",
    "        breaks[breaks==0] = -1\n",
    "        #concatenate data\n",
    "        available_equips = pd.concat([amounts,breaks])\n",
    "    \n",
    "    \n",
    "#     print(available_equips)\n",
    "    #removes second index and sort by date\n",
    "    available_equips = available_equips.reset_index(level=[1])\n",
    "    available_equips = available_equips.drop(['Patrimônio'],axis=1)\n",
    "    available_equips.sort_index(inplace=True)\n",
    "#     print(available_equips)\n",
    "    # Adds a new column 'Quantidade Disponível' with the cumulative sum\n",
    "    available_equips.loc[:,'Quantidade Disponível'] = available_equips.cumsum()[0]\n",
    "#     print(available_equips)\n",
    "    return(available_equips,equip_amount_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_equip_data_to_plot(available_equips,equip_amount_data,start_date,end_date):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    today = pd.to_datetime(date.today()).to_numpy()\n",
    "    \n",
    "    x_data1 = equip_amount_data.index.get_level_values(0).values\n",
    "    y_data1 = equip_amount_data['Quantidade de Equipamentos'].values.astype(int)\n",
    "\n",
    "    x_data2 = available_equips.index.values\n",
    "    y_data2 = available_equips['Quantidade Disponível'].values.astype(int)\n",
    "    \n",
    "#     print('type(x_data1)=',type(x_data1[-1]))\n",
    "#     print('type(x_data2)=',type(x_data2[-1]))\n",
    "#     print('type(end_date)=',type(end_date.to_numpy()))\n",
    "#     print('x_data1=',x_data1[-1])\n",
    "#     print('x_data2=',x_data2[-1])\n",
    "#     print('end_date=',end_date)\n",
    "    \n",
    "#     print('argmax=',np.argmax(np.array([x_data1[-1],x_data2[-1],today])))\n",
    "#     max_date_index = np.argmax(np.array([x_data1[-1],x_data2[-1],today]))\n",
    "    \n",
    "#     if max_date_index==0:\n",
    "#         x_data2 = np.append(x_data2,x_data1[-1])\n",
    "#         y_data2 = np.append(y_data2,y_data2[-1])\n",
    "#     elif max_date_index==1:\n",
    "        \n",
    "#         x_data1 = np.append(x_data1,x_data2[-1])\n",
    "#         y_data1 = np.append(y_data1,y_data1[-1])\n",
    "#     else:\n",
    "    #add last point (today)\n",
    "    x_data1 = np.append(x_data1,today)\n",
    "    x_data1 = pd.to_datetime(x_data1)\n",
    "    y_data1 = np.append(y_data1,y_data1[-1])\n",
    "\n",
    "    x_data2 = np.append(x_data2,today)\n",
    "    x_data2 = pd.to_datetime(x_data2)\n",
    "    y_data2 = np.append(y_data2,y_data2[-1])\n",
    "    # add first point as 0\n",
    "    x_data1 = np.insert(x_data1,0,x_data1[0])\n",
    "    y_data1 = np.insert(y_data1,0,0)\n",
    "    x_data2 = np.insert(x_data2,0,x_data1[0])\n",
    "    y_data2 = np.insert(y_data2,0,0)\n",
    "    \n",
    "    \n",
    "#     if (len(x_data1)>0) & (len(x_data2)>0):\n",
    "#         print('A')\n",
    "#         # Extend first and last points of equip_amount to match available_equips\n",
    "#         if x_data1[0] > x_data2[0]:\n",
    "#             x_data1 = np.insert(x_data1,0,x_data2[0])\n",
    "#             y_data1 = np.insert(y_data1,0,y_data1[0])\n",
    "#         if x_data1[-1] < x_data2[-1]:\n",
    "# #             print('completa final da curva azul')\n",
    "#             x_data1 = np.append(x_data1,x_data2[-1])\n",
    "#             y_data1 = np.append(y_data1,y_data1[-1])\n",
    "#         else:\n",
    "# #             print('completa final da curva laranja')\n",
    "# #             print('x_data2 antes = ',x_data2[-3:])\n",
    "#             x_data2 = np.append(x_data2,x_data1[-1])\n",
    "#             y_data2 = np.append(y_data2,y_data2[-1])\n",
    "# #             print('x_data2 depois = ',x_data2[-3:])\n",
    "#     else:\n",
    "#         if x_data1[0] > start_date:\n",
    "            \n",
    "# #             print('x_data1=',x_data1)\n",
    "#             x_data1 = np.insert(x_data1,0,start_date)\n",
    "#             y_data1 = np.insert(y_data1,0,y_data1[0])\n",
    "#         if x_data1[-1] < end_date:\n",
    "# #             print('x_data1=',x_data1)\n",
    "# #             x_data1 = np.insert(x_data1,-1,start_date)\n",
    "#             x_data1 = np.append(x_data1,end_date.to_numpy())\n",
    "# #             print('x_data1=',x_data1)\n",
    "# #             print(type(x_data1[0]),type(x_data1[-1]))\n",
    "# #             x_data1 = np.concatenate((x_data1,np.array([end_date])))\n",
    "#             x_data1 = pd.to_datetime(x_data1)\n",
    "#             y_data1 = np.append(y_data1,y_data1[-1])\n",
    "# #             print('x_data1=',x_data1)\n",
    "    return(x_data1,y_data1,x_data2,y_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_empty_data(df,start_date,end_date):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    # Checks if dataframe is single index or multiindex\n",
    "    if isinstance(df.index, pd.MultiIndex): \n",
    "        after_start_date = df.index.get_level_values(0) >= start_date\n",
    "        before_end_date = df.index.get_level_values(0) <= end_date\n",
    "        between_two_dates = after_start_date & before_end_date\n",
    "        empty_flag = df[between_two_dates].index.get_level_values(0).empty\n",
    "    else:\n",
    "        after_start_date = df.index >= start_date\n",
    "        before_end_date = df.index <= end_date\n",
    "        between_two_dates = after_start_date & before_end_date\n",
    "        empty_flag = df[between_two_dates].index.empty\n",
    "    return(empty_flag,between_two_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de aquisição de custo de material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_material_cost_data():\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    for file in os.listdir(\".\\MaterialUtilizado\"):\n",
    "        if file.endswith(\".xls\"):\n",
    "            file_path = os.path.join(\".\\MaterialUtilizado\", file)\n",
    "    material_cost_data = pd.read_excel(file_path,skiprows=3,header=2)\n",
    "    material_cost_data['Data Saida'] = pd.to_datetime(material_cost_data['Data Saida'],dayfirst=True)\n",
    "    material_cost_data.sort_values(by=['Data Saida'], inplace=True)  \n",
    "    material_cost_data.set_index(['Data Saida'],inplace=True)\n",
    "    return(material_cost_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_external_cost_data():\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    for file in os.listdir(\".\\ConsertoExterno\"):\n",
    "        if file.endswith(\".xls\"):\n",
    "            file_path = os.path.join(\".\\ConsertoExterno\", file)\n",
    "            \n",
    "    external_cost_data = pd.read_excel('ConsertoExternoPeriodo2011_2021.xls',skiprows=3,header=2)\n",
    "    external_cost_data['Data Encerramento'] = pd.to_datetime(external_cost_data['Data Encerramento'],dayfirst=True)\n",
    "    external_cost_data.sort_values(by=['Data Encerramento'], inplace=True)  \n",
    "    external_cost_data.set_index(['Data Encerramento'],inplace=True)\n",
    "    return(external_cost_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equip_monthly_cost(equip,cost_data):\n",
    "    \n",
    "    import pandas as pd\n",
    "    try:\n",
    "        selected_equip = cost_data['Tipo Equipamento']==equip\n",
    "    except:\n",
    "        selected_equip = cost_data['Tipo']==equip\n",
    "    cost = cost_data[selected_equip]['Custo']\n",
    "    cost = cost.sort_index()\n",
    "    monthly_cost = cost.groupby(pd.Grouper(freq=\"MS\")).sum()  # DataFrameGroupBy (grouped by Month start frequency)\n",
    "    return(monthly_cost)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_cost_data_to_plot(material_monthly_cost,external_monthly_cost,equip_amount_data,start_date,end_date):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    today = pd.to_datetime(date.today()).to_numpy()\n",
    "    \n",
    "    #Apply masks\n",
    "    x_data1 = equip_amount_data.index.get_level_values(0).values\n",
    "    y_data1 = equip_amount_data['Quantidade de Equipamentos'].values.astype(int)\n",
    "    \n",
    "    x_data2 = material_monthly_cost.index.values\n",
    "    y_data2 = material_monthly_cost.values \n",
    "    \n",
    "    x_data3 = external_monthly_cost.index.values\n",
    "    y_data3 = external_monthly_cost.values\n",
    "    \n",
    "    #add last point (today)\n",
    "    x_data1 = np.append(x_data1,today)\n",
    "    x_data1 = pd.to_datetime(x_data1)\n",
    "    y_data1 = np.append(y_data1,y_data1[-1])\n",
    "    \n",
    "    # add first point as 0\n",
    "    x_data1 = np.insert(x_data1,0,x_data1[0])\n",
    "    y_data1 = np.insert(y_data1,0,0)\n",
    "    \n",
    "#     # matches lenghts of x_data2 with x_data3 (add missing dates in x_data and add zeros in missing y_data) \n",
    "#     i=0\n",
    "#     while x_data3[i] < x_data2[i]:\n",
    "#         x_data2 = np.insert(x_data2,i,x_data3[i])\n",
    "#         y_data2 = np.insert(y_data2,0,0)\n",
    "#         i+=1\n",
    "#     i=0\n",
    "#     while x_data2[i] < x_data3[i]:\n",
    "#         x_data3 = np.insert(x_data3,i,x_data2[i])\n",
    "#         y_data3 = np.insert(y_data3,0,0)\n",
    "#         i+=1\n",
    "#     if len(x_data2)>len(x_data3):\n",
    "#         y_data3 = np.append(y_data3,np.zeros(len(x_data2)-len(x_data3)))\n",
    "#         x_data3 = np.append(x_data3,x_data2[len(x_data3):])\n",
    "#         x_data3 = pd.to_datetime(x_data3)\n",
    "#     elif len(x_data2)<len(x_data3):\n",
    "#         y_data2 = np.append(y_data2,np.zeros(len(x_data3)-len(x_data2)))\n",
    "#         x_data2 = np.append(x_data2,x_data3[len(x_data2):])\n",
    "#         x_data2 = pd.to_datetime(x_data2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return(x_data1,y_data1,x_data2,y_data2,x_data3,y_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
